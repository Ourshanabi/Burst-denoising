{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from ImagesloaderRAM import *\n",
    "from Trainfunction import *\n",
    "from Savemodel import *\n",
    "from Mycudatransformation import *\n",
    "from MynnModule import *\n",
    "from PSNR import *\n",
    "\n",
    "import torchvision.transforms as T\n",
    "import torchvision.utils as tu\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "dtype = torch.FloatTensor\n",
    "gpu_dtype = torch.cuda.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cpu\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './SSFD_G_NBnew20000'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-a5935a534a76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load single frame denoiser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mDenoiser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLoad_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./SSFD_G_NBnew20000'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Loading the dataset of images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mDenoiser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMFD_C\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDenoiser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Burst-denoising/Savemodel.py\u001b[0m in \u001b[0;36mLoad_model\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# load a train model and its optimizer in a tuple (model,optimizer)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mLoad_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mSave\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mSave_dic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSave\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './SSFD_G_NBnew20000'"
     ]
    }
   ],
   "source": [
    "# Load single frame denoiser\n",
    "SFDenoiser, optimizer = Load_model('./SSFD_G_NBnew20000')\n",
    "\n",
    "# Loading the dataset of images\n",
    "# We do not load the dataset as it is to big but we can split it.\n",
    "\n",
    "paths=['cl1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SSFD_C' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-fb9940574757>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Choose the model of neural networks architectures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mDenoiser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSSFD_C\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Choose the loss function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL1Loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SSFD_C' is not defined"
     ]
    }
   ],
   "source": [
    "MFDenoiser = MFD_C(SFDenoiser).to(device)\n",
    "\n",
    "loss = nn.L1Loss().to(device)\n",
    "\n",
    "optimizer = optim.Adam(MFDenoiser.parameters(), lr=0.00001, betas=(\n",
    "    0.9, 0.999), eps=1e-08, weight_decay=0.00001, amsgrad=False)\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.9, patience=500, verbose=True,\n",
    "    threshold=0.0001, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "def trainburstserveur(model, paths, loss_fn, optimizer, scheduler, name, Nb_frames=4, batch_size=10, num_epochs=100, nb_subepoch=1000, save_every=1):\n",
    "\n",
    "    tic = time()\n",
    "    model.train()\n",
    "\n",
    "    loss_history = []\n",
    "    loss_sfd_history = []\n",
    "    loss_mfd_history = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
    "\n",
    "        for path in paths:\n",
    "            trainset = 0\n",
    "            trainloader = 0\n",
    "            trainset = Burstfolder(path, 0.1, Nb_frames, MyRandomCrop(\n",
    "                64), Randomnoise=False, loader=RGB_loader, loadram='cpu')\n",
    "            trainloader = torch.utils.data.DataLoader(\n",
    "                trainset, shuffle=False, batch_size=batch_size, drop_last=True)\n",
    "\n",
    "            for subepoch in range(nb_subepoch):\n",
    "                tac = time()\n",
    "                if tac-tic > 36000:\n",
    "                    Save_modelloss(model, optimizer, loss_history,\n",
    "                                   name+'%s ' % int(epoch+1))\n",
    "                    tic = time()\n",
    "\n",
    "                for t, (x, y) in enumerate(trainloader):\n",
    "\n",
    "                    x = Variable(torch.transpose(x.to(device), 0, 1))\n",
    "                    y = Variable(torch.transpose(y.to(device), 0, 1))\n",
    "\n",
    "                    mfinit1, mfinit2, mfinit3, mfinit4, mfinit5, mfinit6, mfinit7 = torch.zeros(\n",
    "                        7, trainloader.batch_size, 64, 64, 64).to(device)\n",
    "                    mfinit8 = torch.zeros(\n",
    "                        trainloader.batch_size, 3, 64, 64).to(device)\n",
    "\n",
    "                    i = 0\n",
    "                    for frame, target in zip(x, y):\n",
    "                        if i == 0:\n",
    "                            i += 1\n",
    "                            dframe, mf1, mf2, mf3, mf4, mf5, mf6, mf7, mf8 = model(\n",
    "                                frame, mfinit1, mfinit2, mfinit3, mfinit4, mfinit5, mfinit6, mfinit7, mfinit8)\n",
    "                            loss_sfd = 0\n",
    "                            loss_sfd = loss_fn(dframe, target)\n",
    "                            loss_mfd = loss_fn(mf8, target)\n",
    "\n",
    "                        else:\n",
    "                            dframe, mf1, mf2, mf3, mf4, mf5, mf6, mf7, mf8 = model(\n",
    "                                frame, mf1, mf2, mf3, mf4, mf5, mf6, mf7, mf8)\n",
    "                            loss_sfd += loss_fn(dframe, target)\n",
    "                            loss_mfd += loss_fn(mf8, target)\n",
    "\n",
    "                    loss = loss_sfd+loss_mfd\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                print('subepoch = %d, loss = %.4f,loss_sfd = %.4f,loss_mfd = %.4f' % (\n",
    "                    subepoch + 1, loss.data, loss_sfd.data, loss_mfd.data))  # loss_mfd.data\n",
    "\n",
    "                loss_sfd_history.append(loss_sfd)\n",
    "                loss_mfd_history.append(loss_mfd)\n",
    "                loss_history.append(loss)\n",
    "\n",
    "                scheduler.step(loss.data)\n",
    "\n",
    "        print('epoch = %d, loss = %.4f' % (epoch + 1, loss.data))\n",
    "        if (epoch+1) % save_every == 0:\n",
    "            Save_modelloss_mfd(model, optimizer, loss_history, loss_sfd_history,\n",
    "                               loss_mfd_history, name+'%s ' % int(epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 500000\n",
      "t = 3, loss = 0.2042\n",
      "Starting epoch 2 / 500000\n",
      "t = 3, loss = 0.1533\n",
      "Starting epoch 3 / 500000\n",
      "t = 3, loss = 0.1045\n",
      "Starting epoch 4 / 500000\n",
      "t = 3, loss = 0.0929\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-4ed63f67c66b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainserver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDenoiser\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'SSFD_C_NB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-36e763c96611>\u001b[0m in \u001b[0;36mtrainserver\u001b[0;34m(model, loader_train, loss_fn, optimizer, scheduler, num_epochs, save_every, loss_every, filename)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainburstserveur(MFDenoiser, paths, loss, optimizer, scheduler, \"MFDCnew\",\n",
    "                  Nb_frames=8, batch_size=13, num_epochs=5, nb_subepoch=100, save_every=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load from a previous training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'SFD_B75000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Denoiser, optimizer, loss = Load_modelloss(filename)\n",
    "loss = nn.L1Loss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainserver(model, loader_train, loss_fn, optimizer, scheduler, num_epochs=1, save_every=1, loss_every=10, filename='denoiser'):\n",
    "\n",
    "    loss_history = []\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
    "        model.train()\n",
    "\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            x_var = Variable(x.to(device))\n",
    "            y_var = Variable(y.to(device))\n",
    "\n",
    "            frame = model(x_var)\n",
    "            loss = loss_fn(frame, y_var)\n",
    "\n",
    "            if (t + 1) % loss_every == 0:\n",
    "                print('t = %d, loss = %.4f' % (t + 1, loss.data))\n",
    "                loss_history.append(loss)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if (epoch+1) % save_every == 0:\n",
    "            Save_modelloss(model, optimizer, loss_history,\n",
    "                           filename+'%s ' % int(epoch+1))\n",
    "\n",
    "        scheduler.step(loss.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainserver(Denoiser, trainloader, loss, optimizer, scheduler,\n",
    "            num_epochs=500000, save_every=25000, loss_every=3, filename=filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test denoiser and save images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_test = T.Compose([\n",
    "    T.ToTensor()])\n",
    "\n",
    "testset = ImageFolderRAM('./CBSD68', 0.1, Data_test,\n",
    "                         Randomnoise=False, loadram=False, loader=RGB_loader)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, shuffle=False, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename1 = 'SFD_25SFD_C_NB75000'\n",
    "filename1 = 'SFD_25SFD_C_NB75000'\n",
    "Denoiser, optimizer, loss = Load_modelloss(filename1)\n",
    "Denoiser2, optimizer, loss2 = Load_modelloss(filename2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Show_result(Denoiser, loader, pause, check=False):\n",
    "    \"\"\"\n",
    "Fonction permettant de montrer les resultats de debuitages d'un reseau de neuronnes\n",
    "Input :\n",
    "    - model : reseau à tester\n",
    "    - loader_train : l'ensemble d'image issu du dataloader\n",
    "    - pause : temps de pause entre chaque image\n",
    "    - check : if True cela affiche la moyenne de l'image, le min , le max\n",
    "\n",
    "Affiche :\n",
    "    -L'image normale\n",
    "    -L'image bruitée\n",
    "    -L'image debruité\n",
    "    -Les PSNR\n",
    "\"\"\"\n",
    "    Denoiser.eval()\n",
    "\n",
    "    plt.ion()\n",
    "    plt.show()\n",
    "\n",
    "    # Calcul de la PSNR moyenne\n",
    "    PSNRmoy = 0\n",
    "    Compteur = 0\n",
    "\n",
    "    for i, data in enumerate(loader):\n",
    "        images, groundtrue = data\n",
    "\n",
    "        plt.figure(1)\n",
    "        plt.clf()\n",
    "        plt.imshow(np.clip(np.transpose(tu.make_grid(\n",
    "            groundtrue, range=(0, 1), nrow=4).numpy(), (1, 2, 0)), 0, 1))\n",
    "        plt.axis('off')\n",
    "\n",
    "        print(\"Image bruitée\")\n",
    "        plt.figure(2)\n",
    "        plt.clf()\n",
    "        plt.imshow(np.clip(np.transpose(tu.make_grid(\n",
    "            images, range=(0, 1), nrow=4).numpy(), (1, 2, 0)), 0, 1))\n",
    "        plt.axis('off')\n",
    "\n",
    "        A = psnr(groundtrue.numpy(), images.numpy(), check=check)\n",
    "        plt.title(r'%f ' % A)\n",
    "\n",
    "        print(\"Image débruitée\")\n",
    "        plt.figure(3)\n",
    "        plt.clf()\n",
    "        images = Denoiser(\n",
    "            Variable(images, requires_grad=False).type(gpu_dtype)).data.cpu()\n",
    "        plt.imshow(np.clip(np.transpose(tu.make_grid(\n",
    "            images, range=(0, 1), nrow=4).numpy(), (1, 2, 0)), 0, 1))\n",
    "        plt.axis('off')\n",
    "\n",
    "        A = psnr(groundtrue.numpy(), images.numpy(), check=check)\n",
    "        PSNRmoy += A\n",
    "        Compteur += 1\n",
    "        plt.title(r'%f ' % A)\n",
    "\n",
    "        plt.pause(pause)\n",
    "\n",
    "    print('PSNR moyen = %f ' % (PSNRmoy/Compteur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Show_result2(Denoiser1, Denoiser2, loader, pause, check=False):\n",
    "    \"\"\"\n",
    "Fonction permettant de comparer les resultats de debuitages d'un reseau de neuronnes\n",
    "Input :\n",
    "    - Denoiser1 : debruiteur 1 à tester\n",
    "    - Denoiser2 : debruiteur 2 à tester\n",
    "    - loader_train : l'ensemble d'image issu du dataloader\n",
    "    - pause : temps de pause entre chaque image\n",
    "    - check : if True cela affiche la moyenne de l'image, le min , le max\n",
    "\n",
    "Affiche :\n",
    "    - L'image normale\n",
    "    - L'image bruitée\n",
    "    - L'image debruité par 1\n",
    "    - L'image debruité par 2\n",
    "    - Les PSNR\n",
    "\"\"\"\n",
    "    Denoiser1.eval()\n",
    "    Denoiser2.eval()\n",
    "\n",
    "    plt.ion()\n",
    "    plt.show()\n",
    "\n",
    "    # Calcul de la PSNR moyenne\n",
    "    PSNRmoy1 = 0\n",
    "    PSNRmoy2 = 0\n",
    "    Compteur = 0\n",
    "\n",
    "    for i, data in enumerate(loader):\n",
    "        images, groundtrue = data\n",
    "\n",
    "        plt.figure(1)\n",
    "        plt.clf()\n",
    "        plt.imshow(np.clip(np.transpose(tu.make_grid(\n",
    "            groundtrue, range=(0, 1), nrow=4).numpy(), (1, 2, 0)), 0, 1))\n",
    "        plt.axis('off')\n",
    "\n",
    "        print(\"Image bruitée\")\n",
    "        plt.figure(2)\n",
    "        plt.clf()\n",
    "        plt.imshow(np.clip(np.transpose(tu.make_grid(\n",
    "            images, range=(0, 1), nrow=4).numpy(), (1, 2, 0)), 0, 1))\n",
    "        plt.axis('off')\n",
    "\n",
    "        A = psnr(groundtrue.numpy(), images.numpy(), check=check)\n",
    "        plt.title(r'%f ' % A)\n",
    "\n",
    "        print(\"Image débruitée par 1\")\n",
    "        plt.figure(3)\n",
    "        plt.clf()\n",
    "        images1 = Denoiser1(\n",
    "            Variable(images, requires_grad=False).type(gpu_dtype)).data.cpu()\n",
    "        plt.imshow(np.clip(np.transpose(tu.make_grid(\n",
    "            images1, range=(0, 1), nrow=4).numpy(), (1, 2, 0)), 0, 1))\n",
    "        plt.axis('off')\n",
    "\n",
    "        A = psnr(groundtrue.numpy(), images1.numpy(), check=check)\n",
    "        PSNRmoy1 += A\n",
    "        Compteur += 1\n",
    "        plt.title(r' Denoiseur1 PSNR=%f ' % A)\n",
    "\n",
    "        print(\"Image débruitée par 2\")\n",
    "        plt.figure(4)\n",
    "        plt.clf()\n",
    "        images2 = Denoiser2(\n",
    "            Variable(images, requires_grad=False).type(gpu_dtype)).data.cpu()\n",
    "        plt.imshow(np.clip(np.transpose(tu.make_grid(\n",
    "            images2, range=(0, 1), nrow=4).numpy(), (1, 2, 0)), 0, 1))\n",
    "        plt.axis('off')\n",
    "\n",
    "        A = psnr(groundtrue.numpy(), images2.numpy())\n",
    "        PSNRmoy2 += A\n",
    "        plt.title(r' Denoiseur2 PSNR= %f ' % A)\n",
    "\n",
    "        plt.pause(pause)\n",
    "\n",
    "    print(' Mean PSNR denoiseur1 = %f ' % (PSNRmoy1/Compteur))\n",
    "    print(' Mean PSNR denoiseur2 = %f ' % (PSNRmoy2/Compteur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For only one denoiser\n",
    "Show_result(Denoiser, testloader, 0.1, check=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To compare 2de\n",
    "Show_result2(Denoiser, Denoiser2, testloader, 0.1, check=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Plot\n",
    "\n",
    "##\n",
    "plt.show()\n",
    "plt.ion()\n",
    "\n",
    "##\n",
    "plt.figure(5)\n",
    "plt.clf()\n",
    "plt.semilogy(range(0, len(loss2))[:10000:10], loss2[:10000:10])\n",
    "\n",
    "plt.figure(6)\n",
    "plt.clf()\n",
    "plt.plot(range(0, len(loss))[:10000:10], loss[:10000:10])\n",
    "\n",
    "##\n",
    "plt.figure(6)\n",
    "plt.clf()\n",
    "plt.plot(range(0, len(loss2))[1::10], loss2[10000::10])\n",
    "\n",
    "\n",
    "##\n",
    "plt.figure(7)\n",
    "plt.clf()\n",
    "plt.plot(range(0, len(loss3)), loss3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
